{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345560e4-06ec-41c3-802e-1444547efc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "\n",
    "class ParkingSpotDetection:\n",
    "    def __init__(self, parking_model_path, vehicle_model_path, ffmpeg_path, confidence_threshold=0.5):\n",
    "        self.parking_model = YOLO(parking_model_path)\n",
    "        self.vehicle_model = YOLO(vehicle_model_path)\n",
    "        self.ffmpeg_path = ffmpeg_path\n",
    "        self.available_spots = set()\n",
    "        self.occupied_spots = set()\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "\n",
    "    def json_yolo(self, parking_spots):\n",
    "        new_parking_spots = []\n",
    "        for bbox in parking_spots:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            polygon = [[int(x1), int(y1)], [int(x2), int(y1)], [int(x2), int(y2)], [int(x1), int(y2)]]\n",
    "            new_parking_spots.append({\"points\": polygon})\n",
    "    \n",
    "        return json.dumps(new_parking_spots, indent=4)\n",
    "\n",
    "    def process_video_with_ffmpeg(self, input_file, output_file=\"video_result.mp4\"):\n",
    "        try:\n",
    "            print(f\"Processing video from {input_file} to {output_file}...\")\n",
    "            result = subprocess.run(\n",
    "                [self.ffmpeg_path, '-y', '-i', input_file, output_file],\n",
    "                check=True,\n",
    "                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                text=True\n",
    "            )\n",
    "            print(result.stdout)\n",
    "            return output_file\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing ffmpeg: {e.stderr}\")\n",
    "            return False\n",
    "\n",
    "    def detect_objects(self, frame, model, threshold):\n",
    "        detections = model(frame)\n",
    "        boxes = detections[0].boxes.xyxy.cpu().numpy()\n",
    "        confidences = detections[0].boxes.conf.cpu().numpy()\n",
    "        class_indices = detections[0].boxes.cls.cpu().numpy()\n",
    "        class_names = detections[0].names\n",
    "\n",
    "        filtered_boxes = []\n",
    "        filtered_class_indices = []\n",
    "        filtered_confidences = []\n",
    "\n",
    "        for box, confidence, class_idx in zip(boxes, confidences, class_indices):\n",
    "            if confidence >= threshold:\n",
    "                filtered_boxes.append(box)\n",
    "                filtered_class_indices.append(class_idx)\n",
    "                filtered_confidences.append(confidence)\n",
    "\n",
    "        return filtered_boxes, filtered_class_indices, filtered_confidences, class_names\n",
    "\n",
    "    def get_centroid(self, bbox):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        return (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    def is_car_in_parking_spot(self, car_bbox, parking_bbox):\n",
    "        cx, cy = self.get_centroid(car_bbox)\n",
    "        px1, py1, px2, py2 = parking_bbox\n",
    "        px1, px2 = min(px1, px2), max(px1, px2)\n",
    "        py1, py2 = min(py1, py2), max(py1, py2)\n",
    "        return px1 <= cx <= px2 and py1 <= cy <= py2\n",
    "\n",
    "    def update_parking_status(self, cars, parkings):\n",
    "        for idx, parking in enumerate(parkings):\n",
    "            parking_occupied = False\n",
    "            for car in cars:\n",
    "                if self.is_car_in_parking_spot(car, parking):\n",
    "                    parking_occupied = True\n",
    "                    break\n",
    "            if parking_occupied:\n",
    "                if idx not in self.occupied_spots:\n",
    "                    self.occupied_spots.add(idx)\n",
    "                if idx in self.available_spots:\n",
    "                    self.available_spots.remove(idx)\n",
    "            else:\n",
    "                if idx not in self.available_spots:\n",
    "                    self.available_spots.add(idx)\n",
    "                if idx in self.occupied_spots:\n",
    "                    self.occupied_spots.remove(idx)\n",
    "\n",
    "    def process_frame(self, frame, parkings_predictions, confidence_threshold_vehicles):\n",
    "        boxes_parkings, class_indices_parkings, confidences_parkings, class_names_parkings = parkings_predictions\n",
    "    \n",
    "        parkings = []\n",
    "        for box, class_idx in zip(boxes_parkings, class_indices_parkings):\n",
    "            if class_names_parkings[int(class_idx)] in ['parking-spot', 'parking-spot-disabled']:\n",
    "                parkings.append(box)\n",
    "    \n",
    "        boxes_vehicles, class_indices_vehicles, confidences_vehicles, class_names_vehicles = self.detect_objects(frame, self.vehicle_model, confidence_threshold_vehicles)\n",
    "        cars = []\n",
    "        for box, class_idx in zip(boxes_vehicles, class_indices_vehicles):\n",
    "            if class_names_vehicles[int(class_idx)] in ['car', 'van', 'truck']:\n",
    "                cars.append(box)\n",
    "\n",
    "        parking_bboxes = []\n",
    "        for d in parkings:\n",
    "            parking_bboxes.append((d[0], d[1], d[2], d[3]))\n",
    "        \n",
    "        self.update_parking_status(cars, parking_bboxes)\n",
    "        \n",
    "        return boxes_vehicles, class_indices_vehicles, confidences_vehicles, class_names_vehicles\n",
    "\n",
    "    def draw_bboxes(self, frame, boxes, class_indices, confidences, class_names, color):\n",
    "        for box, class_idx, confidence in zip(boxes, class_indices, confidences):\n",
    "            x1, y1, x2, y2 = box\n",
    "            label = class_names[int(class_idx)]\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "\n",
    "    def draw_bboxes_parking_spots(self, frame, boxes, class_indices, class_names):\n",
    "        for i, (box, class_idx) in enumerate(zip(boxes, class_indices)):\n",
    "            x1, y1, x2, y2 = box\n",
    "            label = class_names[int(class_idx)]\n",
    "    \n",
    "            if i in self.occupied_spots:\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                color = (0, 255, 0)\n",
    "    \n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "            #cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "        available_count = len(self.available_spots)\n",
    "        occupied_count = len(self.occupied_spots)\n",
    "        cv2.putText(frame, f\"Available: {available_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Occupied: {occupied_count}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "        return frame\n",
    "\n",
    "    \n",
    "    def draw_bboxes_vehicles(self, frame, boxes, class_indices, confidences, class_names):\n",
    "        for box, class_idx, confidence in zip(boxes, class_indices, confidences):\n",
    "            x1, y1, x2, y2 = box\n",
    "            label = class_names[int(class_idx)]\n",
    "            if label == 'car' or 'van' or 'truck':\n",
    "                color = (255, 0, 0)\n",
    "        \n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                #cv2.putText(frame, f\"{label} ({confidence:.2f})\", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "        return frame\n",
    "\n",
    "\n",
    "    def process_video_gradio(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        assert cap.isOpened(), \"Error opening video file\"\n",
    "    \n",
    "        w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "        ret, frame_parking = cap.read()\n",
    "        assert ret, \"Error reading parking frame\"\n",
    "    \n",
    "        # Detect parking spots in the first frame\n",
    "        parkings_predictions = self.detect_objects(frame_parking, self.parking_model, self.confidence_threshold)\n",
    "        class_names_parkings = parkings_predictions[3]\n",
    "        boxes_parkings = []\n",
    "        class_indices_parkings = []\n",
    "        confidences_parkings = []\n",
    "        for box, class_idx, confidence in zip(parkings_predictions[0], parkings_predictions[1], parkings_predictions[2]):\n",
    "            if parkings_predictions[3][int(class_idx)] in ['parking-spot', 'parking-spot-disabled']:\n",
    "                boxes_parkings.append(box)\n",
    "                class_indices_parkings.append(class_idx)\n",
    "                confidences_parkings.append(confidence)\n",
    "    \n",
    "        # Prepare video writer\n",
    "        output_path = \"processed_video.mp4\"\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "    \n",
    "        # Process video frames\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "    \n",
    "            # Detect vehicles in the current frame\n",
    "            vehicle_detections = self.process_frame(frame, parkings_predictions, 0.7)\n",
    "    \n",
    "            # Draw bounding boxes for parking spots and vehicles\n",
    "            frame = self.draw_bboxes_parking_spots(frame, boxes_parkings, class_indices_parkings, class_names_parkings)\n",
    "            frame = self.draw_bboxes_vehicles(frame, *vehicle_detections)\n",
    "    \n",
    "            video_writer.write(frame)\n",
    "    \n",
    "        cap.release()\n",
    "        video_writer.release()\n",
    "    \n",
    "        # Return processed video path and parking spot JSON\n",
    "        return self.process_video_with_ffmpeg(output_path), self.json_yolo(boxes_parkings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65946497-25a5-4651-87f5-aa97953f4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_object_detection(video, conf_threshold):\n",
    "    detector = ParkingSpotDetection(\n",
    "        parking_model_path=\"../app/models/yolo11n-detect-parking.pt\",\n",
    "        vehicle_model_path=\"../app/models/yolov8n-visdrone.pt\",\n",
    "        ffmpeg_path=r\"C:\\ffmpeg\\ffmpeg-7.1-essentials_build\\bin\\ffmpeg.exe\",\n",
    "        confidence_threshold=conf_threshold\n",
    "    )\n",
    "    return detector.process_video_gradio(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10aafa1e-4f94-4eee-aa34-7c6734f39f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def create_interface():\n",
    "    video = gr.Video(label=\"Video Source\")\n",
    "    conf_threshold = gr.Slider(\n",
    "        label=\"Parking Spots Confidence Threshold\",\n",
    "        minimum=0.0,\n",
    "        maximum=1.0,\n",
    "        step=0.05,\n",
    "        value=0.70,\n",
    "    )\n",
    "    output_video = gr.Video(label=\"Processed Video\")\n",
    "    output_json = gr.JSON(label=\"Detection Info\")\n",
    "\n",
    "    interface = gr.Interface(\n",
    "        fn=stream_object_detection,\n",
    "        inputs=[video, conf_threshold],\n",
    "        outputs=[output_video, output_json],\n",
    "    )\n",
    "\n",
    "    interface.launch()\n",
    "\n",
    "create_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15463083-9aaf-43bf-bc4a-a08eb813016f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
